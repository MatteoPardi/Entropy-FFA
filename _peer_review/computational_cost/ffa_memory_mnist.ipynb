{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a08dc49",
   "metadata": {
    "id": "4a08dc49"
   },
   "source": [
    "# Memory Consuming. MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87379ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../_tools/')\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as trasf\n",
    "from utils.tensordata import TDataset, TDataloader, PosNeg_Bootstrap_TDataloader\n",
    "from ffa import FFA_withEntropy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "th.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
    "th.cuda.synchronize(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadaea4",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f7c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_torch_dataset = torchvision.datasets.MNIST(\n",
    "    root=r\"C:\\Users\\matte\\LocalData\\Master Thesis\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=trasf.ToTensor()\n",
    ")\n",
    "TS_torch_dataset = torchvision.datasets.MNIST(\n",
    "    root=r\"C:\\Users\\matte\\LocalData\\Master Thesis\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=trasf.ToTensor()\n",
    ")\n",
    "\n",
    "# Load everything\n",
    "DS = TDataset(\n",
    "    x=th.stack([x.flatten() for x, y in DS_torch_dataset]).to(device),\n",
    "    y=th.tensor([y for x, y in DS_torch_dataset], device=device).reshape(-1, 1)\n",
    ")\n",
    "TS = TDataset(\n",
    "    x=th.stack([x.flatten() for x, y in TS_torch_dataset]).to(device),\n",
    "    y=th.tensor([y for x, y in TS_torch_dataset], device=device).reshape(-1, 1)\n",
    ")\n",
    "TR, VL = DS.random_split(5/6)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 128\n",
    "DS_dl = DS.dataloader(batch_size=batch_size)\n",
    "TR_dl = TR.dataloader(batch_size=batch_size)\n",
    "VL_dl = VL.dataloader(batch_size=batch_size)\n",
    "TS_dl = TS.dataloader(batch_size=batch_size)\n",
    "TR_pndl = PosNeg_Bootstrap_TDataloader(TR, batch_size=batch_size)\n",
    "DS_pndl = PosNeg_Bootstrap_TDataloader(DS, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74216c3",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127c40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = FFA_withEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439db02",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d56cd",
   "metadata": {},
   "source": [
    "Warm up model. As first model to test, a trash one will be used, to be sure that every pytorch 'just-first-time' memory allocations have been allocated when interesting models are tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd1c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_warmup = {\n",
    "    'Nclasses': 10,\n",
    "    'A': (784+10, 20),\n",
    "    'f_hid': nn.ReLU(),\n",
    "    'lr_hot': 0.01,\n",
    "    'lr_cold': 0.01,\n",
    "    'momentum': 0.99, \n",
    "    'weight_decay': 0.0001,\n",
    "    'temperature': 0,\n",
    "    'kernel_scale': 10.,\n",
    "    'Nepochs': 2\n",
    "}  \n",
    "\n",
    "exps = {}\n",
    "exps['warmup'] = hyp_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4390e7",
   "metadata": {},
   "source": [
    "Final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b8f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_Toff20 = {\n",
    "    'Nclasses': 10,\n",
    "    'A': (784+10, 20, 20, 20),\n",
    "    'f_hid': nn.ReLU(),\n",
    "    'lr_hot': 0.01,\n",
    "    'lr_cold': 0.01,\n",
    "    'momentum': 0.99, \n",
    "    'weight_decay': 0.0001,\n",
    "    'temperature': 0,\n",
    "    'kernel_scale': 10., # the value found in 'T on' experiment, to compare the value of H\n",
    "    'Nepochs': 2\n",
    "}\n",
    "hyp_Toff200 = {\n",
    "    'Nclasses': 10,\n",
    "    'A': (784+10, 200, 200, 200),\n",
    "    'f_hid': nn.ReLU(),\n",
    "    'lr_hot': 0.05,\n",
    "    'lr_cold': 0.05,\n",
    "    'momentum': 0.99, \n",
    "    'weight_decay': 1e-8,\n",
    "    'temperature': 0,\n",
    "    'kernel_scale': 90., # the value found in 'T on' experiment, to compare the value of H\n",
    "    'Nepochs': 2\n",
    "}\n",
    "hyp_Toff2000 = {\n",
    "    'Nclasses': 10,\n",
    "    'A': (784+10, 2000, 2000, 2000),\n",
    "    'f_hid': nn.ReLU(),\n",
    "    'lr_hot': 0.1,\n",
    "    'lr_cold': 0.1,\n",
    "    'momentum': 0.995, \n",
    "    'weight_decay': 1e-8,\n",
    "    'temperature': 0,\n",
    "    'kernel_scale': 900., # the value found in 'T on' experiment, to compare the value of H\n",
    "    'Nepochs': 2\n",
    "}\n",
    "hyp_Ton20 = {\n",
    "    'Nclasses': 10,\n",
    "    'A': (784+10, 20, 20, 20),\n",
    "    'f_hid': nn.ReLU(),\n",
    "    'lr_hot': 0.01,\n",
    "    'lr_cold': 0.01,\n",
    "    'momentum': 0.99, \n",
    "    'weight_decay': 0.0001,\n",
    "    'temperature': 0.1/3,\n",
    "    'kernel_scale': 10.,\n",
    "    'Nepochs': 2\n",
    "}\n",
    "hyp_Ton200 = {\n",
    "    'Nclasses': 10,\n",
    "    'A': (784+10, 200, 200, 200),\n",
    "    'f_hid': nn.ReLU(),\n",
    "    'lr_hot': 0.05,\n",
    "    'lr_cold': 0.05,\n",
    "    'momentum': 0.99, \n",
    "    'weight_decay': 1e-6,\n",
    "    'temperature': 3,\n",
    "    'kernel_scale': 90.,\n",
    "    'Nepochs': 2\n",
    "}\n",
    "hyp_Ton2000 = {\n",
    "    'Nclasses': 10,\n",
    "    'A': (784+10, 2000, 2000, 2000),\n",
    "    'f_hid': nn.ReLU(),\n",
    "    'lr_hot': 0.1,\n",
    "    'lr_cold': 0.1,\n",
    "    'momentum': 0.995, \n",
    "    'weight_decay': 1e-8,\n",
    "    'temperature': 30.,\n",
    "    'kernel_scale': 900.,\n",
    "    'Nepochs': 2\n",
    "}\n",
    "\n",
    "exps |= {\n",
    "    'Toff20': hyp_Toff20,\n",
    "    'Toff200': hyp_Toff200,\n",
    "    'Toff2000': hyp_Toff2000,\n",
    "    'Ton20': hyp_Ton20,\n",
    "    'Ton200': hyp_Ton200,\n",
    "    'Ton2000': hyp_Ton2000,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260cdccb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a402a00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup: (baseline: 210.995 MB) 9.34326 MB\n",
      "Toff20: (baseline: 215.573 MB) 4.771 MB\n",
      "Toff200: (baseline: 215.573 MB) 6.70996 MB\n",
      "Toff2000: (baseline: 215.573 MB) 109.155 MB\n",
      "Ton20: (baseline: 215.573 MB) 4.771 MB\n",
      "Ton200: (baseline: 215.573 MB) 14.5952 MB\n",
      "Ton2000: (baseline: 215.573 MB) 202.446 MB\n"
     ]
    }
   ],
   "source": [
    "class MemoryAnalyzer:\n",
    "    \n",
    "    def __init__ (self, device):\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def reset (self):\n",
    "\n",
    "        th.cuda.reset_peak_memory_stats(device)\n",
    "        th.cuda.synchronize(device)\n",
    "        self._base_value = th.cuda.max_memory_allocated(device) \n",
    "    \n",
    "    def get_max_gap (self):\n",
    "        \n",
    "        return (th.cuda.max_memory_allocated(device) - self._base_value)/1024/1024 #MByte\n",
    "  \n",
    "ma = MemoryAnalyzer(device)\n",
    "for exp, hyp in exps.items():\n",
    "    print(exp, end=': ')\n",
    "    ma.reset()\n",
    "    print(f\"(baseline: {ma._base_value/1024/1024:.6g} MB)\", end=' ')\n",
    "    m = Model(hyp).to(device)\n",
    "    m.fit(DS_pndl)\n",
    "    memory = ma.get_max_gap()\n",
    "    print(f\"{memory:.6g} MB\")\n",
    "    del m, memory"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
